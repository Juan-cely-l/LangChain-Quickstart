{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "env_setup_first",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import getpass\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "dotenv_path = Path('.env')\n",
    "if not dotenv_path.exists():\n",
    "    dotenv_path = Path('..') / '.env'\n",
    "load_dotenv(dotenv_path=dotenv_path)\n",
    "\n",
    "required_vars = [\"GEMINI_API_KEY\"]\n",
    "for var in required_vars:\n",
    "    if not os.getenv(var):\n",
    "        os.environ[var] = getpass.getpass(f\"Enter {var}: \")\n",
    "\n",
    "# Avoid provider key conflicts in mixed environments.\n",
    "if os.getenv(\"GEMINI_API_KEY\"):\n",
    "    os.environ.pop(\"GOOGLE_API_KEY\", None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ea28d1",
   "metadata": {},
   "source": [
    "# LangChain LLM Chain Tutorial "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9544ad1",
   "metadata": {},
   "source": [
    "## Environment Setup\n",
    "Install dependencies using `requirements.txt` as described in the repository README."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc1c06a7",
   "metadata": {},
   "source": [
    "## Build a basic agent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ed1459f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [HumanMessage(content='what is the weather in sf', additional_kwargs={}, response_metadata={}, id='949bdfe7-d69b-4dd2-8fbd-5a8a6b0c0c2b'), AIMessage(content='', additional_kwargs={'function_call': {'name': 'get_weather', 'arguments': '{\"city\": \"San Francisco\"}'}, '__gemini_function_call_thought_signatures__': {'38edd0ca-f20b-4bf2-8013-ee90e60b9cd4': 'CocCAb4+9vulKkfAD9Hc53Sllyxhpd/4tn22rWz3XP6bMpWbRGeU6ffgHjxcuko0mcNuImu9wMTDdxdSgm5M1XNQm2tN/pd2WTEiBUQ3zZ5ItrcxCai3dVdgbei3p6ugamSU0CJYkJTYJhn+aQOTvRkE2nTtSW0VuDjK2mimtmWqLNLwJdt0b0F8vnF87qUH/VeFNTuXh0WvCigzrqCva78NYf374mKt+axEHXxfktqCsFpoCEtZmDVK7z+cFle+rTof/KxsFEV8/wmq8B4gNxRb1mb5sZK02rTElcfwOvd6Zte4Bt13v6qi/di4ic5PNkiumPpBjyDz5la3mfn2khbD2n/ZGzWphd0='}}, response_metadata={'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': [], 'model_provider': 'google_genai'}, id='lc_run--019c78a7-dc73-72f3-a7ee-4a6e73fe4cae-0', tool_calls=[{'name': 'get_weather', 'args': {'city': 'San Francisco'}, 'id': '38edd0ca-f20b-4bf2-8013-ee90e60b9cd4', 'type': 'tool_call'}], invalid_tool_calls=[], usage_metadata={'input_tokens': 50, 'output_tokens': 72, 'total_tokens': 122, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 56}}), ToolMessage(content=\"It's always sunny in San Francisco!\", name='get_weather', id='65435084-bbeb-43ae-ad1e-ccc392a9d15e', tool_call_id='38edd0ca-f20b-4bf2-8013-ee90e60b9cd4'), AIMessage(content='The weather in San Francisco is always sunny!', additional_kwargs={}, response_metadata={'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': [], 'model_provider': 'google_genai'}, id='lc_run--019c78a7-e1c8-7f12-8594-212b81296c84-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 89, 'output_tokens': 9, 'total_tokens': 98, 'input_token_details': {'cache_read': 0}})]}\n"
     ]
    }
   ],
   "source": [
    "from langchain.agents import create_agent\n",
    "\n",
    "def get_weather(city: str) -> str:\n",
    "    \"\"\"Herramienta de ejemplo.\"\"\"\n",
    "    return f\"It's always sunny in {city}!\"\n",
    "\n",
    "agent = create_agent(\n",
    "    model=\"google_genai:gemini-2.5-flash\",   \n",
    "    tools=[get_weather],\n",
    "    system_prompt=\"You are a helpful assistant\",\n",
    ")\n",
    "\n",
    "result = agent.invoke({\n",
    "    \"messages\": [{\"role\": \"user\", \"content\": \"what is the weather in sf\"}]\n",
    "})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a9ef118",
   "metadata": {},
   "source": [
    "# Build a real-world agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a772884e",
   "metadata": {},
   "source": [
    "### Build a Practical Weather Forecasting Agent\n",
    "\n",
    "This example demonstrates key production concepts:\n",
    "\n",
    "1. **Detailed system prompts** for better agent behavior\n",
    "2. **External data integration** via custom tools\n",
    "3. **Model configuration** for consistent responses\n",
    "4. **Structured output** for predictable results\n",
    "5. **Conversational memory** for chat-like interactions\n",
    "6. **End-to-end testing** by running the fully functional agent\n",
    "\n",
    "Let's walk through each step:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91193f4d",
   "metadata": {},
   "source": [
    "## 1. Define the system prompt\n",
    "\n",
    "The system prompt defines your agentâ€™s role and behavior. Keep it specific and actionable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b9d853d",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT = \"\"\"You are an expert weather forecaster, who speaks in puns.\n",
    "\n",
    "You have access to two tools:\n",
    "\n",
    "- get_weather_for_location: use this to get the weather for a specific location\n",
    "- get_user_location: use this to get the user's location\n",
    "\n",
    "If a user asks you for the weather, make sure you know the location. If you can tell from the question that they mean wherever they are, use the get_user_location tool to find their location.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9233c6c1",
   "metadata": {},
   "source": [
    "## 2. Create tools\n",
    "\n",
    "\n",
    "Tools let a model interact with external systems by calling functions you define. Tools can depend on runtime context and also interact with agent memory.\n",
    "Notice below how the get_user_location tool uses runtime context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13a25bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from langchain.tools import tool, ToolRuntime\n",
    "\n",
    "@tool\n",
    "def get_weather_for_location(city: str) -> str:\n",
    "    \"\"\"Get weather for a given city.\"\"\"\n",
    "    return f\"It's always sunny in {city}!\"\n",
    "\n",
    "@dataclass\n",
    "class Context:\n",
    "    \"\"\"Custom runtime context schema.\"\"\"\n",
    "    user_id: str\n",
    "\n",
    "@tool\n",
    "def get_user_location(runtime: ToolRuntime[Context]) -> str:\n",
    "    \"\"\"Retrieve user information based on user ID.\"\"\"\n",
    "    user_id = runtime.context.user_id\n",
    "    return \"Florida\" if user_id == \"1\" else \"SF\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ab25e6d",
   "metadata": {},
   "source": [
    "## 3. Configure the model\n",
    "Set up the language model with the right parameters for your use case:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "333aa287",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "model = init_chat_model(\n",
    "    \"google_genai:gemini-2.5-flash\",\n",
    "    api_key=os.environ[\"GEMINI_API_KEY\"],\n",
    "    temperature=0.5,\n",
    "    timeout=10,\n",
    "    max_tokens=1000,\n",
    "    max_retries=2,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d796eb23",
   "metadata": {},
   "source": [
    "## 4.Define response format\n",
    "Optionally, define a structured response format if you need the agent responses to match a specific schema.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9ad297b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "# We use a dataclass here, but Pydantic models are also supported.\n",
    "@dataclass\n",
    "class ResponseFormat:\n",
    "    \"\"\"Response schema for the agent.\"\"\"\n",
    "    # A punny response (always required)\n",
    "    punny_response: str\n",
    "    # Any interesting information about the weather if available\n",
    "    weather_conditions: str | None = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e97396c8",
   "metadata": {},
   "source": [
    "## 5. Add memory\n",
    "\n",
    "Add memory to your agent to maintain state across interactions. This allows the agent to remember previous conversations and context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "09248e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "\n",
    "checkpointer = InMemorySaver()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6573b613",
   "metadata": {},
   "source": [
    "## 6. Create and run the agent\n",
    "Now assemble your agent with all the components and run it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f4a0f8eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResponseFormat(punny_response='Looks like the weather in Florida is quite a *bright* spot! Hope you have a *sun-sational* day!', weather_conditions=\"It's always sunny in Florida!\")\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain.agents import create_agent\n",
    "from langchain.agents.structured_output import ToolStrategy\n",
    "\n",
    "model = init_chat_model(\n",
    "    \"google_genai:gemini-2.5-flash\",\n",
    "    api_key=os.environ[\"GEMINI_API_KEY\"],\n",
    "    temperature=0.3,\n",
    "    timeout=20,\n",
    "    max_tokens=800,\n",
    ")\n",
    "\n",
    "agent = create_agent(\n",
    "    model=model,\n",
    "    system_prompt=SYSTEM_PROMPT,\n",
    "    tools=[get_user_location, get_weather_for_location],\n",
    "    context_schema=Context,\n",
    "    response_format=ToolStrategy(ResponseFormat),\n",
    "    checkpointer=checkpointer,\n",
    ")\n",
    "\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "response = agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"what is the weather outside?\"}]},\n",
    "    config=config,\n",
    "    context=Context(user_id=\"1\"),\n",
    ")\n",
    "\n",
    "print(response[\"structured_response\"])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
